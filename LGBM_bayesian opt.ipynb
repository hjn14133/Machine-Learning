{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGB_Regression_Yield.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTcIBVx/pl6ihBYwPZgFvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjn14133/Machine-Learning/blob/main/LGBM_bayesian%20opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5QOvdGkzdB-",
        "outputId": "1cc475c2-dccc-4219-a023-27eeaf8038c5"
      },
      "source": [
        "!pip install bayesian-optimization"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11685 sha256=d50f85815ccaf483e61e447fc3d87700a3311f6eef5f6c6e5a0fd65a286f1647\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/9b/71/f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ACpA_BjzjwC",
        "outputId": "b30497fb-961b-407a-e5d3-133a4c35cc0c"
      },
      "source": [
        "! pip install scikit-optimize"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 100 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRIuEKwVzzBw",
        "outputId": "43c16faf-922a-4d7b-dcff-b18643b81267"
      },
      "source": [
        "! pip install shap"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.40.0.tar.gz (371 kB)\n",
            "\u001b[K     |████████████████████████████████| 371 kB 5.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.62.3)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n",
            "Building wheels for collected packages: shap\n",
            "  Building wheel for shap (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.40.0-cp37-cp37m-linux_x86_64.whl size=509236 sha256=bbd94de987f3df7feadb0b27ab98fdc4ad58c91a8b7c81b373f40112efd68661\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/35/84/e304841ac4b910bc95fe9a6e5302eb2507b4333728851dcbfb\n",
            "Successfully built shap\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.40.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJB0f0n_4_uR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import time\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import lightgbm as lgb\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSNQ_jh56XCB"
      },
      "source": [
        "df = pd.read_csv(\"FT_join_JH_cleaned.csv\")\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZdVksZY6fSo"
      },
      "source": [
        "X = df[['DISTANCE', 'Heading','Elevation', 'AppliedRat']]\n",
        "y = df['VRYIELDBAL']\n",
        "\n",
        "# y = df['Loan_Rat']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdGbRBFHbs4D"
      },
      "source": [
        "# Perform data splitting using 80/20 ratio\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRwGPw2oLvNn"
      },
      "source": [
        "def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
        "    params = {'application':'binary','num_iterations':4000, 'learning_rate':0.05, 'early_stopping_round':100, 'metric':'auc'}\n",
        "    params[\"num_leaves\"] = round(num_leaves)\n",
        "    params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
        "    params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
        "    params['max_depth'] = round(max_depth)\n",
        "    params['lambda_l1'] = max(lambda_l1, 0)\n",
        "    params['lambda_l2'] = max(lambda_l2, 0)\n",
        "    params['min_split_gain'] = min_split_gain\n",
        "    params['min_child_weight'] = min_child_weight\n",
        "    cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
        "    return max(cv_result['auc-mean'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfIoe5cbNGpB"
      },
      "source": [
        "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
        "                                        'feature_fraction': (0.1, 0.9),\n",
        "                                        'bagging_fraction': (0.8, 1),\n",
        "                                        'max_depth': (5, 8.99),\n",
        "                                        'lambda_l1': (0, 5),\n",
        "                                        'lambda_l2': (0, 3),\n",
        "                                        'min_split_gain': (0.001, 0.1),\n",
        "                                        'min_child_weight': (5, 50)}, random_state=0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "l6Lq47pz1iRH",
        "outputId": "a258619a-a961-447c-a2aa-60490adee1e5"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "def label_encoder(input_df, encoder_dict=None):\n",
        "    \"\"\" Process a dataframe into a form useable by LightGBM \"\"\"\n",
        "    # Label encode categoricals\n",
        "    categorical_feats = input_df.columns[input_df.dtypes == 'object']\n",
        "    for feat in categorical_feats:\n",
        "        encoder = LabelEncoder()\n",
        "        input_df[feat] = encoder.fit_transform(input_df[feat].fillna('NULL'))\n",
        "    return input_df, categorical_feats.tolist(), encoder_dict\n",
        "application_train, categorical_feats, encoder_dict = label_encoder(application_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-bfc4849a0419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minput_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NULL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mapplication_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplication_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'application_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "JT9r8kJL0_ow",
        "outputId": "ab98ee27-bc47-42d3-af7a-90872999911e"
      },
      "source": [
        "def bayes_parameter_opt_lgb(X_train, Y_train, init_round=15, opt_round=25, n_folds=5, random_seed=6, n_estimators=10000, learning_rate=0.05, output_process=False):\n",
        "    # prepare data\n",
        "    train_data = lgb.Dataset(data=X_train, label=Y_train, categorical_feature = categorical_feats, free_raw_data=False)\n",
        "    # parameters\n",
        "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
        "        params = {'application':'binary','num_iterations': n_estimators, 'learning_rate':learning_rate, 'early_stopping_round':100, 'metric':'auc'}\n",
        "        params[\"num_leaves\"] = int(round(num_leaves))\n",
        "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
        "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
        "        params['max_depth'] = int(round(max_depth))\n",
        "        params['lambda_l1'] = max(lambda_l1, 0)\n",
        "        params['lambda_l2'] = max(lambda_l2, 0)\n",
        "        params['min_split_gain'] = min_split_gain\n",
        "        params['min_child_weight'] = min_child_weight\n",
        "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
        "        return max(cv_result['auc-mean'])\n",
        "    # range \n",
        "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
        "                                            'feature_fraction': (0.1, 0.9),\n",
        "                                            'bagging_fraction': (0.8, 1),\n",
        "                                            'max_depth': (5, 8.99),\n",
        "                                            'lambda_l1': (0, 5),\n",
        "                                            'lambda_l2': (0, 3),\n",
        "                                            'min_split_gain': (0.001, 0.1),\n",
        "                                            'min_child_weight': (5, 50)}, random_state=0)\n",
        "    # optimize\n",
        "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
        "    \n",
        "    # output optimization process\n",
        "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
        "    \n",
        "    # return best parameters\n",
        "    return lgbBO.res['max']['max_params']\n",
        "\n",
        "opt_params = bayes_parameter_opt_lgb(X_train, Y_train, init_round=5, opt_round=10, n_folds=3, random_seed=6, n_estimators=100, learning_rate=0.05)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-552a9fe95ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlgbBO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mopt_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayes_parameter_opt_lgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-552a9fe95ccf>\u001b[0m in \u001b[0;36mbayes_parameter_opt_lgb\u001b[0;34m(X_train, Y_train, init_round, opt_round, n_folds, random_seed, n_estimators, learning_rate, output_process)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbayes_parameter_opt_lgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_raw_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlgb_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_leaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_fraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbagging_fraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_l1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_l2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_split_gain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'categorical_feats' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKU6EetR1AEl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}