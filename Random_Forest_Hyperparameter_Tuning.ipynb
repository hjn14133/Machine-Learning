{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random Forest Hyperparameter Tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPj6X7XMObgMyIZay9+nzs3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjn14133/Machine-Learning/blob/main/Random_Forest_Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "PKbmU8WHIwln",
        "outputId": "7f276aa8-1e91-4e85-d513-799ef9fdcd60"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "features = pd.read_csv('temps.csv')\n",
        "\n",
        "features = features.drop(['forecast_noaa', 'forecast_acc', 'forecast_under',\n",
        "                          'month', 'day', 'week'] , \n",
        "              axis = 1)\n",
        "\n",
        "print(features.shape)\n",
        "features.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(348, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>temp_2</th>\n",
              "      <th>temp_1</th>\n",
              "      <th>average</th>\n",
              "      <th>actual</th>\n",
              "      <th>friend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016</td>\n",
              "      <td>45</td>\n",
              "      <td>45</td>\n",
              "      <td>45.6</td>\n",
              "      <td>45</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016</td>\n",
              "      <td>44</td>\n",
              "      <td>45</td>\n",
              "      <td>45.7</td>\n",
              "      <td>44</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016</td>\n",
              "      <td>45</td>\n",
              "      <td>44</td>\n",
              "      <td>45.8</td>\n",
              "      <td>41</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016</td>\n",
              "      <td>44</td>\n",
              "      <td>41</td>\n",
              "      <td>45.9</td>\n",
              "      <td>40</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016</td>\n",
              "      <td>41</td>\n",
              "      <td>40</td>\n",
              "      <td>46.0</td>\n",
              "      <td>44</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  temp_2  temp_1  average  actual  friend\n",
              "0  2016      45      45     45.6      45      29\n",
              "1  2016      44      45     45.7      44      61\n",
              "2  2016      45      44     45.8      41      56\n",
              "3  2016      44      41     45.9      40      53\n",
              "4  2016      41      40     46.0      44      41"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXP1JSo6JURW",
        "outputId": "05ac0053-d89b-49d7-f621-4323758c43ed"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(random_state = 42)\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# Look at parameters used by current forest\n",
        "print('Parameters currently in use: \\n')\n",
        "pprint(rf.get_params())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters currently in use: \n",
            "\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'criterion': 'mse',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 42,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw4-U2E7KYxF",
        "outputId": "7ddd6398-06a4-4084-b29b-4297caeca572"
      },
      "source": [
        "# Try a set of hyperparameters by creating Random Grid\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Number of trees in rabdom forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, \n",
        "                                             stop = 2000, \n",
        "                                             num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "pprint(random_grid)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeQcdD3SKBwu"
      },
      "source": [
        "# Use random grid to search for best hyperparameters\n",
        "# First creat the base model to tune\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Random search of parameters using 3 fold cross validation\n",
        "# Search across 100 different combinations and use all available cores\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator= rf, \n",
        "                               param_distributions= random_grid,\n",
        "                               n_iter = 100, \n",
        "                               cv=3, \n",
        "                               verbose=2,\n",
        "                               random_state = 42,\n",
        "                               n_jobs = -1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mu6PdzeNYs3"
      },
      "source": [
        "labels = np.array(features['actual'])\n",
        "\n",
        "features= features.drop('actual', axis = 1)\n",
        "\n",
        "# Training and Testing Sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features,\n",
        "                                                                            labels,\n",
        "                                                                            test_size = 0.25,\n",
        "                                                                            random_state = 42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZtdkUXPNuhH",
        "outputId": "b1babe87-798a-40d6-f876-4e854129b08f"
      },
      "source": [
        "# Fit the random search model (Running the models... 6 mins in total)\n",
        "rf_random.fit(train_features, train_labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   44.1s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.9min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestRegressor(bootstrap=True,\n",
              "                                                   ccp_alpha=0.0,\n",
              "                                                   criterion='mse',\n",
              "                                                   max_depth=None,\n",
              "                                                   max_features='auto',\n",
              "                                                   max_leaf_nodes=None,\n",
              "                                                   max_samples=None,\n",
              "                                                   min_impurity_decrease=0.0,\n",
              "                                                   min_impurity_split=None,\n",
              "                                                   min_samples_leaf=1,\n",
              "                                                   min_samples_split=2,\n",
              "                                                   min_weight_fraction_leaf=0.0,\n",
              "                                                   n_estimators=100,\n",
              "                                                   n_jobs=None, oob_score=Fals...\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
              "                                                      70, 80, 90, 100, 110,\n",
              "                                                      None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [200, 400, 600, 800,\n",
              "                                                         1000, 1200, 1400, 1600,\n",
              "                                                         1800, 2000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2Wli08cQD51",
        "outputId": "7d3e06aa-caa5-421a-a02e-f46b638179b2"
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 90,\n",
              " 'max_features': 'sqrt',\n",
              " 'min_samples_leaf': 4,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 1800}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ3n4nB8QG9d"
      },
      "source": [
        "# Compare base model with the best random search model\n",
        "# Evaluate Random Search \n",
        "def evaluate(model, test_features, test_labels):\n",
        "  predictions = model.predict(test_features)\n",
        "  errors = abs(predictions - test_labels)\n",
        "  mape = 100 * np.mean(errors/test_labels)\n",
        "  accuracy = 100 - mape\n",
        "  print('Model Performance')\n",
        "  print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "  print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "  return accuracy"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TUUojqtRS5j",
        "outputId": "1bbb4643-fb05-473d-9fb1-e1798ca32f33"
      },
      "source": [
        "base_model = RandomForestRegressor(n_estimators= 10,\n",
        "                                   random_state = 42)\n",
        "base_model.fit(train_features, train_labels)\n",
        "base_accuracy = evaluate(base_model, test_features, test_labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance\n",
            "Average Error: 4.0345 degrees.\n",
            "Accuracy = 93.51%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqO1VjrPRtFX",
        "outputId": "368b545b-63b7-43d9-9298-f606973b9832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "best_random = rf_random.best_estimator_\n",
        "random_accuracy = evaluate(best_random, test_features, test_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance\n",
            "Average Error: 3.4980 degrees.\n",
            "Accuracy = 94.47%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tRyK8DXR93v",
        "outputId": "9bbd8172-aca2-44e7-ba9b-afb721dbf544",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Improvement of {:0.2f}%'.format(100*(random_accuracy- base_accuracy)/base_accuracy))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improvement of 1.02%\n"
          ]
        }
      ]
    }
  ]
}